{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Ray Pneumonia detection with convolutional neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd       \n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt    \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize all random units to the same seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "# this may not work with old tensorflow versions\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the global variables used during the code:\n",
    "  - AUTOTUNE For monitoring and optimization. It is used when preparing the data for training.\n",
    "  -  BATCH_SIZE The number of images taken for each group while training.\n",
    "  -  IMAGE_SIZE This variable is the size of the scans after preprocessing.\n",
    "  -  EPOCHS The iterations of the training.\n",
    "  -  IMAGE_CROP The percentage of image we want to keep, when applying central cropping [0,1].\n",
    "  -  RANDOM_STATE We added the Random State to compare the results not depending on the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"scaled_chest_xray\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = [180, 180]\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "IMAGE_CROP = 1\n",
    "RANDOM_STATE = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "\n",
    "The Chest X-ray data we are using from https://www.kaggle.com/datasets/tolgadincer/labeled-chest-xray-images divides the data into train and test files. We will append the test files and create a new split.\n",
    "- 20% test files\n",
    "- 64% training files\n",
    "- 16% validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_CNN = tf.io.gfile.glob(str(train_dir + '/*/*'))\n",
    "filenames_CNN.extend(tf.io.gfile.glob(str(test_dir + '/*/*')))\n",
    "\n",
    "# Split arrays or matrices into random train and test subsets.\n",
    "t_filenames_CNN, test_filenames_CNN = train_test_split(filenames_CNN, test_size=0.2, random_state = RANDOM_STATE)\n",
    "train_filenames_CNN, val_filenames_CNN = train_test_split(t_filenames_CNN, test_size=0.2, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_NORMAL_train_CNN = len([filename for filename in train_filenames_CNN if \"NORMAL\" in filename])\n",
    "print(\"Normal images count in training set: \" + str(COUNT_NORMAL_train_CNN))\n",
    "\n",
    "COUNT_PNEUMONIA_train_CNN = len([filename for filename in train_filenames_CNN if \"PNEUMONIA\" in filename])\n",
    "print(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA_train_CNN))\n",
    "print(\"Sum: \" + str(len(train_filenames_CNN)))\n",
    "print('---------------------------')\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "COUNT_NORMAL_val_CNN = len([filename for filename in val_filenames_CNN if \"NORMAL\" in filename])\n",
    "print(\"Normal images count in validation set: \" + str(COUNT_NORMAL_val_CNN))\n",
    "\n",
    "COUNT_PNEUMONIA_val_CNN = len([filename for filename in val_filenames_CNN if \"PNEUMONIA\" in filename])\n",
    "print(\"Pneumonia images count in validation set: \" + str(COUNT_PNEUMONIA_val_CNN))\n",
    "print(\"Sum: \" + str(len(val_filenames_CNN)))\n",
    "print('---------------------------')\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "COUNT_NORMAL_test_CNN = len([filename for filename in test_filenames_CNN if \"NORMAL\" in filename])\n",
    "print(\"Normal images count in test set: \" + str(COUNT_NORMAL_test_CNN))\n",
    "\n",
    "COUNT_PNEUMONIA_test_CNN = len([filename for filename in test_filenames_CNN if \"PNEUMONIA\" in filename])\n",
    "print(\"Pneumonia images count in test set: \" + str(COUNT_PNEUMONIA_test_CNN))\n",
    "print(\"Sum: \" + str(len(test_filenames_CNN)) + '\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are way more images classified as PNEUMONIA than NORMAL in the training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(n,p,name):\n",
    "    X_axis = np.arange(len(name))\n",
    "    fig = plt.figure(figsize=(8, 6), dpi=80)\n",
    "    \n",
    "    plt.bar(X_axis - 0.2, n, 0.4, label = 'Normal(0)')\n",
    "    plt.bar(X_axis + 0.2, p, 0.4, label = 'Pneumonia(1)')\n",
    "\n",
    "    plt.xticks(X_axis, name)\n",
    "    plt.xlabel('Sets', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.title('Number of cases in sets', fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot visualizes the imbalance of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results \n",
    "plot_dataset([COUNT_NORMAL_train_CNN, COUNT_NORMAL_val_CNN, COUNT_NORMAL_test_CNN], [COUNT_PNEUMONIA_train_CNN, COUNT_PNEUMONIA_val_CNN, COUNT_PNEUMONIA_test_CNN], ['train', 'validation', 'test'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we only have 3 arrays of filenames.\n",
    "We will now create datasets from the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_ds_CNN = tf.data.Dataset.from_tensor_slices(train_filenames_CNN)\n",
    "val_list_ds_CNN = tf.data.Dataset.from_tensor_slices(val_filenames_CNN)\n",
    "test_list_ds_CNN = tf.data.Dataset.from_tensor_slices(test_filenames_CNN)\n",
    "\n",
    "print('Some example filenames: \\n')\n",
    "for f in train_list_ds_CNN.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of elements in the datasets should be the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_COUNT_CNN = tf.data.experimental.cardinality(train_list_ds_CNN).numpy()\n",
    "print(\"Training images count: \" + str(TRAIN_IMG_COUNT_CNN))\n",
    "\n",
    "VAL_IMG_COUNT_CNN = tf.data.experimental.cardinality(val_list_ds_CNN).numpy()\n",
    "print(\"Validating images count: \" + str(VAL_IMG_COUNT_CNN))\n",
    "\n",
    "TEST_IMG_COUNT_CNN = tf.data.experimental.cardinality(test_list_ds_CNN).numpy()\n",
    "print(\"Testing images count: \" + str(TEST_IMG_COUNT_CNN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that there are only two class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "CLASS_NAMES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently our dataset is just a list of filenames. In CNN we want to map each filename to the corresponding (image, label) pair. The following methods will help us do that.\n",
    "As we only have two labels, we will rewrite the label so that 1 or True indicates pneumonia and 0 or False indicates normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == \"PNEUMONIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function that applies Gaussian Noise to the images.\n",
    "'''\n",
    "def add_gaussian_noise(img):\n",
    "    # image must be scaled in [0, 1]\n",
    "    with tf.name_scope('Add_gaussian_noise'):\n",
    "        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=(200)/(255), dtype=tf.float32)\n",
    "        noise_img = img + noise\n",
    "        noise_img = tf.clip_by_value(noise_img, 0.0, 1.0)\n",
    "    return noise_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # For keeping only a portion of the image\n",
    "    img = tf.image.central_crop(img, IMAGE_CROP)\n",
    "    # For adding some noise\n",
    "    #img = add_gaussian_noise(img)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, IMAGE_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method gets the image and the label from the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_CNN = train_list_ds_CNN.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds_CNN = val_list_ds_CNN.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds_CNN = test_list_ds_CNN.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds_CNN.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())\n",
    "  plt.imshow(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the dataset\n",
    "\n",
    "Let's use buffered prefetching so we can yield data from disk without having I/O become blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "      if isinstance(cache, str):\n",
    "          ds = ds.cache(cache)\n",
    "      else:\n",
    "          ds = ds.cache()\n",
    "\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_CNN = prepare_for_training(train_ds_CNN)\n",
    "val_ds_CNN = prepare_for_training(val_ds_CNN)\n",
    "test_ds_CNN = test_ds_CNN.batch(BATCH_SIZE)\n",
    "\n",
    "image_batch_CNN, label_batch_CNN = next(iter(train_ds_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(16):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        if label_batch[n]:\n",
    "            plt.title(\"PNEUMONIA\")\n",
    "        else:\n",
    "            plt.title(\"NORMAL\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(image_batch_CNN.numpy(), label_batch_CNN.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the CNN\n",
    "\n",
    "To make our model more modular and easier to understand, let's define some blocks. As we're building a convolution neural network, we'll create a convolution block and a dense layer block.\n",
    "\n",
    "The architecture for this CNN has been inspired by this article.\n",
    "\n",
    "Convolutional block is composed of of two separable convolution layers, max-pooling and batch-normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "  block = tf.keras.Sequential([\n",
    "      tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "      tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.MaxPool2D()\n",
    "  ]\n",
    "  )\n",
    "\n",
    "  return block"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dense block is built using a dense layer, a batch normalization and a dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(units, dropout_rate):\n",
    "  block = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(units, activation='relu'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "  ])\n",
    "  \n",
    "  return block"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is built using an input layer, two convolutional layers and a MaxPooling one. The following structure is composed of convolutional blocks, dropout layers (to reduce overfitting), a flatten layer, three dense blocks and finally a dense layer.\n",
    "\n",
    "The following method will define the function to build our model for us. The Dropout layers are important as they \"drop out,\" hence the name, certain nodes to reduce the likelikhood of the model overfitting. We want to end the model with a Dense layer of one node, as this will be the output that determines if an X-ray shows an image of pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        \n",
    "        conv_block(32),\n",
    "        conv_block(64),\n",
    "        \n",
    "        conv_block(128),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        conv_block(256),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        dense_block(512, 0.7),\n",
    "        dense_block(128, 0.5),\n",
    "        dense_block(64, 0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solve the problem of data imbalance\n",
    "### Calculate class weights\n",
    "The goal is to identify fraudulent transactions, but you don't have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to \"pay more attention\" to examples from an under-represented class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = (1 / COUNT_NORMAL_train_CNN) * (TRAIN_IMG_COUNT_CNN / 2.0)\n",
    "weight_for_1 = (1 / COUNT_PNEUMONIA_train_CNN) * (TRAIN_IMG_COUNT_CNN / 2.0)\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the model\n",
    "\n",
    "Since there are only two possible labels for the image, we will be using the binary_crossentropy loss. When we fit the model, identify the class weights. Because we are using a TPU, training will be relatively quick.\n",
    "\n",
    "For our metrics, we want to include precision and recall as they will provide use with a more informed picture of how good our model is. Accuracy tells us what fractions are the labels are correct. Since our data is not balanced, accuracy might give a skewed sense of a good model (i.e. a model that always predicts PNEUMONIA will be 74% accurate but is not a good model).\n",
    "\n",
    "In the following part of the code we build our model, define the metrics that should be used to evaluate it, we define the optimizer and the loss function. The activation function are ReLU throughout except for the last layer where it is Sigmoid, as this is a binary classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model()\n",
    "\n",
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds_CNN,\n",
    "    steps_per_epoch=TRAIN_IMG_COUNT_CNN // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds_CNN,\n",
    "    validation_steps=VAL_IMG_COUNT_CNN // BATCH_SIZE,\n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, prec, rec = model.evaluate(test_ds_CNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Finetuning the model\n",
    "\n",
    "In order to finetune our model, we'll need some training callbacks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xRayNet.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "Assuming the goal of a training is to minimize the loss. With this, the metric to be monitored would be 'loss', and mode would be 'min'. A model.fit() training loop will check at end of every epoch whether the loss is no longer decreasing, considering the min_delta and patience if applicable. Once it's found no longer decreasing, model.stop_training is marked True and the training terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "  patience=10,\n",
    "  restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "  k = 0.1\n",
    "  lrate = initial_learning_rate * np.exp(-k*epoch)\n",
    "  return lrate\n",
    "\n",
    "lr_schedule_cb = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrain our model and use the defined callbacks to further increase the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds_CNN,\n",
    "    steps_per_epoch=TRAIN_IMG_COUNT_CNN // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds_CNN,\n",
    "    validation_steps=VAL_IMG_COUNT_CNN // BATCH_SIZE,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint_cb, earlyStopping_cb, lr_schedule_cb],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model performance and evaluation of results\n",
    "\n",
    "### Get the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_CNN = (model.predict(test_ds_CNN, batch_size=16) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the original labels of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the original labels of each image\n",
    "orig_test_labels = []\n",
    "for image, label in test_ds_CNN.as_numpy_iterator():\n",
    "    for x in label:\n",
    "        orig_test_labels.append(x)\n",
    "print(np.array(orig_test_labels).shape)\n",
    "print(np.array(preds_CNN).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(orig_test_labels))\n",
    "print(np.array(preds_CNN).flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **confusion matrix** is convinient to understand how the predictions went.\n",
    "\n",
    "![](assets/confusionMatrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "cm_CNN  = confusion_matrix(orig_test_labels, preds_CNN)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_CNN,figsize=(10,6), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_CNN, acc_CNN, prec_CNN, rec_CNN = model.evaluate(test_ds_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluate function calculating...')\n",
    "print(\"Recall of the model is {:.3f}\".format(rec_CNN))\n",
    "print(\"Precision of the model is {:.3f}\".format(prec_CNN))\n",
    "\n",
    "# Checking if the results are correct by manually calculating Precision and Recall with confusion matrix results\n",
    "print('\\nManually calculating...')\n",
    "tn, fp, fn, tp = cm_CNN.ravel()\n",
    "\n",
    "precision_CNN = tp/(tp+fp)\n",
    "recall_CNN = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.3f}\".format(recall_CNN))\n",
    "print(\"Precision of the model is {:.3f}\".format(precision_CNN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c15c83bb13a6661006366ccb85eabb9cb3c78a2a67451438f95b14adcf94997"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
